---
title: '2025 AI 趋势前瞻：从对话到行动 (LAMs) —— 当 AI 学会了点击鼠标'
description: '大语言模型 (LLM) 已经解决了“听懂人话”的问题，2025 年的焦点是 Large Action Model (LAM)，通过它，AI 将真正接入数字世界的 UI，替我们完成繁琐的操作。'
pubDate: '2026-01-29'
heroImage: '../../../assets/blog-placeholder-1.jpg'
---

如果说 2023-2024 年是 **LLM (Large Language Model, 大语言模型)** 的高光时刻，它们学会了写诗、写代码、通过图灵测试；那么 2025 年无疑是 **LAM (Large Action Model, 大型行动模型)** 的元年。

AI 终于不再满足于做一个只会在聊天框里打字的“键盘侠”，它开始长出了“手”，试图接管我们的鼠标和键盘，去点击 APP，去填写表单，去操作那些设计给人类使用的用户界面 (UI)。

## 什么是 LAM？为什么我们需要它？

### LLM 的局限性
想象一下，你想订一张下周去东京的机票。
*   **LLM 能够**：给你列出航空公司对比，告诉你那个季节东京的天气，甚至帮你写好请假条。
*   **LLM 不能**：真正帮你打开携程或 Expedia，选好航班，输入你的护照号，点击“支付”按钮。

因为 LLM 输出的是 **Text (文本)**，而现实世界的许多任务需要 **Action (行动)**。

### LAM 的定义
LAM 是一种经过特殊训练的模型，它理解的不仅仅是自然语言，还有 **GUI (图形用户界面)**。由于对屏幕截图、DOM 树、API 调用的理解，它可以将用户的意图转化为一系列具体的操作步骤。

> **Rabbit R1 的启示**：虽然 2024 年 Rabbit R1 的硬件发布充满了争议，但它提出的 LAM 概念方向是正确的。它试图让 AI 学习如何像人一样操作 Spotify, Uber 等软件，而不是依赖这些软件是否开放了 API。

## 技术原理：AI 是如何“看见”并“点击”的？

实现 LAM 主要有两条技术路线，而在 2026 年，这两条路线正在融合。

### 1. 基于 API 的功能调用 (Function Calling)
这是目前的过渡方案。像 OpenAI 的 Assistant API，你给它定义一系列工具（如 `get_weather`, `book_flight`），模型会输出 JSON 格式的调用指令。
*   **优点**：准确、稳定。
*   **缺点**：受限于服务商是否开放 API。如果某个 App 没有 API，AI 就束手无策。

### 2. 基于视觉的 UI 操作 (Visual UI Action)
这是 LAM 的终极形态。AI 像人类一样“看”屏幕（通过 Computer Vision 技术）。
1.  **感知 (See)**：模型分析当前屏幕截图，识别出哪里是按钮，哪里是输入框，哪里是下拉菜单。
2.  **规划 (Plan)**：根据用户指令“帮我点一杯拿铁”，规划路径 -> 打开外卖App -> 点击搜索 -> 输入拿铁 -> 选购 -> 结算。
3.  **执行 (Act)**：模拟鼠标移动和键盘输入。

**Multi-Modal (多模态)** 技术的发展让这一路线成为现实。GPT-4V 和 Gemini 1.5 Pro 已经展现了惊人的屏幕理解能力。

## 2025-2026 的应用场景爆发

### 1. 软件操作自动化 (RPA 2.0)
传统的 RPA (机器人流程自动化) 需要程序员死板地录制脚本，一旦 UI 只有一点变动（比如按钮位置挪了 5 像素），脚本就挂了。
LAM 驱动的 RPA 是**语义级别**的。它找的是“提交按钮”，而不是“坐标 (800, 600)”。即使界面大改版，只要逻辑没变，AI 依然能找到按钮。这将彻底重构企业内部的报销、审批、数据录入流程。

### 2. 超级个人助理
手机 OS 层面将内置系统级的 LAM。
*   Siri / Android Assistant 不再是废物。你可以说：“把你刚才发给我的那张照片修一下，发到朋友圈，配文说我即使加班也要热爱生活。”
*   AI 会自动打开相册 -> 调用修图功能 -> 打开微信 -> 编辑朋友圈 -> 发送。整个过程行云流水。

## 面临的挑战：安全与信任

赋予 AI “行动权”比赋予它“说话权”危险一万倍。

*   **误操作风险**：如果 AI 理解错了，把“转账 100 元”理解成了“转账 10000 元”，或者把邮件发给了错误的人，后果不堪设想。
*   **人机验证 (Human-in-the-loop)**：2026 年的设计规范中，所有涉及敏感操作（支付、删除、发送），必须有一个“人类确认”的环节。AI 只能负责填写，点击“确定”的手指必须是人类的。

## 结语

从 LLM 到 LAM，是 AI 从**Info-Provider (信息提供者)** 向 **Service-Provider (服务提供者)** 的跨越。我们即将迎来一个“动口不动手”的时代。在这个时代，最宝贵的技能不再是操作复杂的软件，而是清晰地表达你的意图。
